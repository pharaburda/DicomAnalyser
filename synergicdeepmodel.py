# -*- coding: utf-8 -*-
"""SynergicDeepModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e0E9Rrl_q4rMr7K5SuHBueH99Q46al4b
"""

import torch
import torchvision.models as models
from torch import nn, optim
import math
from torchvision import datasets
from torchvision.transforms import transforms
import os
from torchvision.utils import save_image
import torch.utils.data
import torch.nn.functional as F
from PIL import Image
import time
import re

device = 'cuda:0'

class SynergicNet(nn.Module):
    def __init__(self):
      super(SynergicNet, self).__init__()
      self.conv1 = nn.Conv1d(1, 32, 1)
      self.conv2 = nn.Conv1d(32, 64, 1)
      self.fc1 = nn.Linear(4096, 128)
      self.fc2 = nn.Linear(128, 2)

    def forward(self, first, second):
      x = torch.cat((first, second), 1).unsqueeze(1)
      x = torch.flatten(x, 1)
      x = self.fc1(x)
      x = self.fc2(x)
      output = F.softmax(x, dim=1)
      return output


def initialize_model(use_pretrained=True):
    torch.manual_seed(10)
    first_component = models.resnet50(pretrained=use_pretrained).to(device)
    second_component = models.resnet50(pretrained=use_pretrained).to(device)

    first_component.fc = nn.Identity()
    second_component.fc = nn.Identity()

    synergicNet = SynergicNet().to(device)
    return first_component, second_component, synergicNet

def save_checkpoint(epoch):
    path = "drive/My Drive/checkpoint.pt"
    torch.save({
            'epoch': epoch,
            'first_component_state_dict': first_component.state_dict(),
            'second_component_state_dict': second_component.state_dict(),
            'synergic_component_state_dict': synergicNet.state_dict(),
            'optimizer_1_state_dict': optimizer1.state_dict(),
            'optimizer_2_state_dict': optimizer2.state_dict(),
            'optimizer_S_state_dict': optimizerS.state_dict()
            }, path)
    
def load_checkpoint():
    path = "drive/My Drive/checkpoint.pt"
    checkpoint = torch.load(path)
    epoch = checkpoint['epoch']
    first_component.load_state_dict(checkpoint['first_component_state_dict'])
    second_component.load_state_dict(checkpoint['second_component_state_dict'])
    synergicNet.load_state_dict(checkpoint['synergic_component_state_dict'])
    optimizer1.load_state_dict(checkpoint['optimizer_1_state_dict'])
    optimizer2.load_state_dict(checkpoint['optimizer_2_state_dict'])
    optimizerS.load_state_dict(checkpoint['optimizer_S_state_dict'])

    return epoch

def train_model(num_epochs=10, use_checkpoint=False):
    since = time.time()
    start_epoch = 0
    if (use_checkpoint):
      start_epoch = load_checkpoint()

    for epoch in range(start_epoch, num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                first_component.train()
                second_component.train()
                synergicNet.train()
                
            else:
                first_component.eval()
                second_component.eval()
                synergicNet.eval()
            
            running_loss_1 = 0.0
            running_corrects_1 = 0
            running_loss_2 = 0.0
            running_corrects_2 = 0
            running_loss_s = 0.0
            running_corrects_s = 0

            for (inputs1, labels1), (inputs2, labels2) in zip(imageloader_1[phase], imageloader_2[phase]):
                inputs1 = inputs1.to(device)
                labels1 = labels1.to(device)
                # for inputs2, labels2 in imageloader_2[phase]:
                inputs2 = inputs2.to(device)
                labels2 = labels2.to(device)

                with torch.set_grad_enabled(phase == 'train'):
                  optimizer1.zero_grad()
                  outputs1 = first_component(inputs1).to(device)
                  loss1 = criterion(outputs1, labels1)

                  if phase == 'train':
                      loss1.backward(retain_graph=True)
                      optimizer1.step()
                  
                  _, preds1 = torch.max(outputs1, 1)
                  running_loss_1 += loss1.item() * inputs1.size(0)
                  running_corrects_1 += torch.sum(preds1 == labels1.data)
                  
                  optimizer2.zero_grad()
                  outputs2 = second_component(inputs2).to(device)
                  loss2 = criterion(outputs2, labels2)

                  if phase == 'train':
                      loss2.backward(retain_graph=True)
                      optimizer2.step()

                  _, preds2 = torch.max(outputs2, 1)
                  running_loss_2 += loss2.item() * inputs2.size(0)
                  running_corrects_2 += torch.sum(preds2 == labels2.data)

                  out_1 = first_component(inputs1).to(device)
                  out_2 = second_component(inputs2).to(device)
                  optimizerS.zero_grad()
                  output = synergicNet(out_1, out_2)
                  label = 1 if labels1==labels2 else 0
                  label = torch.LongTensor([label]).to(device)
                  with torch.set_grad_enabled(phase == 'train'):
                      lossS = criterion(output, label)
                      if phase == 'train':
                          lossS.backward()
                          optimizerS.step()
                  _, preds_s = torch.max(output, 1)
                  running_loss_s += lossS.item() * (inputs1.size(0) + inputs2.size(0)) 
                  running_corrects_s += torch.sum(preds_s == label.data)

            calculations_count = len(imageloader_1[phase].dataset)
            epoch_loss_1 = running_loss_1 / calculations_count
            epoch_acc_1 = running_corrects_1.double() / calculations_count

            epoch_loss_2 = running_loss_2 / calculations_count
            epoch_acc_2 = running_corrects_2.double() / calculations_count

            epoch_loss_s = running_loss_s / calculations_count
            epoch_acc_s = running_corrects_s.double() / calculations_count

            print('{} First component loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss_1, epoch_acc_1))
            print('{} Second component loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss_2, epoch_acc_2))
            print('{} Synergic component loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss_s, epoch_acc_s))

            save_checkpoint(epoch)

    print()
    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))

torch.autograd.set_detect_anomaly(True)

data_dir = '/content/drive/My Drive/magisterka'
input_size = (224, 224)
transform = transforms.Compose([
        transforms.Resize(input_size),
        transforms.ToTensor()
    ])

image_dataset = {x: datasets.ImageFolder(os.path.join(data_dir, x), transform) for x in ['train', 'val']}
dataset_len = {x: len(image_dataset[x]) for x in ['train', 'val']}
half_len = {x: int(len(image_dataset[x]) /2) for x in ['train', 'val']}

subset_1 = {}
subset_2 = {}
for x in ['train', 'val']:
  s_1, s_2 = torch.utils.data.random_split(image_dataset[x], [half_len[x], half_len[x]])
  subset_1[x] = s_1
  subset_2[x] = s_2

imageloader_1 = {x: torch.utils.data.DataLoader(subset_1[x], shuffle=True, num_workers=4) for x in ['train', 'val']}
imageloader_2 = {x: torch.utils.data.DataLoader(subset_2[x], shuffle=True, num_workers=4) for x in ['train', 'val']}

first_component, second_component, synergicNet = initialize_model()

params_to_update = []
for param in first_component.parameters():
  params_to_update.append(param)
for param in second_component.parameters():
  params_to_update.append(param)
for param in synergicNet.parameters():
  params_to_update.append(param)

optimizer1 = optim.SGD(first_component.parameters(), lr=0.001, momentum=0.9)
optimizer2 = optim.SGD(second_component.parameters(), lr=0.001, momentum=0.9)
optimizerS = optim.SGD(params_to_update, lr=0.001, momentum=0.9)

criterion = nn.CrossEntropyLoss()

output = train_model()

!pip install dask

!pip install graphviz

!pip install toolz

from graphviz import Digraph
import torch
from torch.autograd import Variable

def make_dot(var, params=None):
    """ Produces Graphviz representation of PyTorch autograd graph
    Blue nodes are the Variables that require grad, orange are Tensors
    saved for backward in torch.autograd.Function
    Args:
        var: output Variable
        params: dict of (name, Variable) to add names to node that
            require grad (TODO: make optional)
    """
    if params is not None:
        assert isinstance(params.values()[0], Variable)
        param_map = {id(v): k for k, v in params.items()}

    node_attr = dict(style='filled',
                     shape='box',
                     align='left',
                     fontsize='12',
                     ranksep='0.1',
                     height='0.2')
    dot = Digraph(node_attr=node_attr, graph_attr=dict(size="12,12"))
    seen = set()

    def size_to_str(size):
        return '('+(', ').join(['%d' % v for v in size])+')'

    def add_nodes(var):
        if var not in seen:
            if torch.is_tensor(var):
                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')
            elif hasattr(var, 'variable'):
                u = var.variable
                name = param_map[id(u)] if params is not None else ''
                node_name = '%s\n %s' % (name, size_to_str(u.size()))
                dot.node(str(id(var)), node_name, fillcolor='lightblue')
            else:
                dot.node(str(id(var)), str(type(var).__name__))
            seen.add(var)
            if hasattr(var, 'next_functions'):
                for u in var.next_functions:
                    if u[0] is not None:
                        dot.edge(str(id(u[0])), str(id(var)))
                        add_nodes(u[0])
            if hasattr(var, 'saved_tensors'):
                for t in var.saved_tensors:
                    dot.edge(str(id(t)), str(id(var)))
                    add_nodes(t)
    add_nodes(var.grad_fn)
    return dot

make_dot(output).view()

data_dir = '/content/drive/My Drive/magisterka/train'
output_dir = data_dir + '/diabetic retinopathy/'
GLAUCOMA = 2
AMD = 0
DR = 1
flip_suffix = '_flip.jpg'
rotated_suffix = '_rotated.jpg'

input_size = (224, 224)
transform = transforms.Compose([
        transforms.Resize(input_size),
        transforms.ToTensor()
    ])
flipTransform =  transforms.Compose([
        transforms.Resize(input_size),
        transforms.RandomHorizontalFlip(p=1),
        transforms.ToTensor()
    ])

rotationTransform =  transforms.Compose([
        transforms.Resize(input_size),
        transforms.RandomRotation(degrees=10, resample=Image.BICUBIC),
        transforms.ToTensor()
    ])

cropTransform =  transforms.Compose([
        transforms.Resize(input_size),
        transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0), ratio=(1.0, 1.2)),
        transforms.ToTensor()
    ])

image_dataset = datasets.ImageFolder(os.path.join(data_dir), rotationTransform)
for file_path, file_class in image_dataset.imgs:
  #print(file_path, file_class)
  if file_class == DR:
    file_name = os.path.splitext(os.path.basename(file_path))[0]
    idx = image_dataset.imgs.index((file_path, file_class))
    save_image(image_dataset[idx][0], output_dir + file_name + rotated_suffix)

import os
glaucoma_dir = '/content/drive/My Drive/magisterka/train/glaucoma'
glaucoma_len= len([name for name in os.listdir(glaucoma_dir) if os.path.isfile(os.path.join(glaucoma_dir, name))])
print(glaucoma_len) 

retinopathy_dir = '/content/drive/My Drive/magisterka/train/diabetic retinopathy'
retinopathy_len= len([name for name in os.listdir(retinopathy_dir) if os.path.isfile(os.path.join(retinopathy_dir, name))])
print(retinopathy_len) 

amd_dir = '/content/drive/My Drive/magisterka/train/amd'
amd_len= len([name for name in os.listdir(amd_dir) if os.path.isfile(os.path.join(amd_dir, name))])
print(amd_len)