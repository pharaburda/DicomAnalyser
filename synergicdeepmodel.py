# -*- coding: utf-8 -*-
"""SynergicDeepModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e0E9Rrl_q4rMr7K5SuHBueH99Q46al4b
"""

import torch
import torchvision.models as models
from torch import nn, optim
import math
from torchvision import datasets
from torchvision.transforms import transforms
import os
from torchvision.utils import save_image
import torch.utils.data
import torch.nn.functional as F

device = 'cuda:0'

class SynergicNet(nn.Module):
    def __init__(self):
      super(SynergicNet, self).__init__()
      self.conv1 = nn.Conv1d(1, 32, 1)
      self.conv2 = nn.Conv1d(32, 64, 1)
      self.fc1 = nn.Linear(4096, 128)
      self.fc2 = nn.Linear(128, 2)

    def forward(self, first, second):
      x = torch.cat((first, second), 1).unsqueeze(1)
      x = torch.flatten(x, 1)
      x = self.fc1(x)
      x = self.fc2(x)
      output = F.softmax(x, dim=1)
      return output


def initialize_model(use_pretrained=True):
    torch.manual_seed(10)
    first_component = models.resnet50(pretrained=use_pretrained).to(device)
    second_component = models.resnet50(pretrained=use_pretrained).to(device)

    first_component.fc = nn.Identity()
    second_component.fc = nn.Identity()

    synergicNet = SynergicNet().to(device)
    return first_component, second_component, synergicNet

def train_model(num_epochs=10):

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                first_component.train()
                second_component.train()
                synergicNet.train()
                
            else:
                first_component.eval()
                second_component.eval()
                synergicNet.eval()

            for inputs1, labels1 in imageloader_1[phase]:
                inputs1 = inputs1.to(device)
                labels1 = labels1.to(device)
                for inputs2, labels2 in imageloader_2[phase]:
                    inputs2 = inputs2.to(device)
                    labels2 = labels2.to(device)

                    with torch.set_grad_enabled(phase == 'train'):
                      optimizer1.zero_grad()
                      outputs1 = first_component(inputs1).to(device)
                      loss1 = criterion(outputs1, labels1)

                      if phase == 'train':
                          loss1.backward(retain_graph=True)
                          optimizer1.step()
                      
                      optimizer2.zero_grad()
                      outputs2 = second_component(inputs2).to(device)
                      loss2 = criterion(outputs2, labels2)

                      if phase == 'train':
                          loss2.backward(retain_graph=True)
                          optimizer2.step()

                    out_1 = first_component(inputs1).to(device)
                    out_2 = second_component(inputs2).to(device)
                    optimizerS.zero_grad()
                    output = synergicNet(out_1, out_2)
                    label = 1 if labels1==labels2 else 0
                    label = torch.LongTensor([label]).to(device)
                    with torch.set_grad_enabled(phase == 'train'):
                        lossS = criterion(output, label)
                        if phase == 'train':
                            lossS.backward()
                            optimizerS.step()

torch.autograd.set_detect_anomaly(True)

data_dir = '/content/drive/My Drive/magisterka_test'
input_size = (224, 224)
transform = transforms.Compose([
        transforms.Resize(input_size),
        transforms.ToTensor()
    ])

image_dataset = {x: datasets.ImageFolder(os.path.join(data_dir, x), transform) for x in ['train', 'val']}
dataset_len = {x: len(image_dataset[x]) for x in ['train', 'val']}
half_len = {x: int(len(image_dataset[x]) /2) for x in ['train', 'val']}

subset_1 = {}
subset_2 = {}
for x in ['train', 'val']:
  s_1, s_2 = torch.utils.data.random_split(image_dataset[x], [half_len[x], half_len[x]])
  subset_1[x] = s_1
  subset_2[x] = s_2

imageloader_1 = {x: torch.utils.data.DataLoader(subset_1[x], shuffle=True, num_workers=4) for x in ['train', 'val']}
imageloader_2 = {x: torch.utils.data.DataLoader(subset_2[x], shuffle=True, num_workers=4) for x in ['train', 'val']}

first_component, second_component, synergicNet = initialize_model()

params_to_update = []
for param in first_component.parameters():
  params_to_update.append(param)
for param in second_component.parameters():
  params_to_update.append(param)
for param in synergicNet.parameters():
  params_to_update.append(param)

optimizer1 = optim.SGD(first_component.parameters(), lr=0.001, momentum=0.9)
optimizer2 = optim.SGD(second_component.parameters(), lr=0.001, momentum=0.9)
optimizerS = optim.SGD(params_to_update, lr=0.001, momentum=0.9)

criterion = nn.CrossEntropyLoss()

output = train_model()

!pip install dask

!pip install graphviz

!pip install toolz

from graphviz import Digraph
import torch
from torch.autograd import Variable

def make_dot(var, params=None):
    """ Produces Graphviz representation of PyTorch autograd graph
    Blue nodes are the Variables that require grad, orange are Tensors
    saved for backward in torch.autograd.Function
    Args:
        var: output Variable
        params: dict of (name, Variable) to add names to node that
            require grad (TODO: make optional)
    """
    if params is not None:
        assert isinstance(params.values()[0], Variable)
        param_map = {id(v): k for k, v in params.items()}

    node_attr = dict(style='filled',
                     shape='box',
                     align='left',
                     fontsize='12',
                     ranksep='0.1',
                     height='0.2')
    dot = Digraph(node_attr=node_attr, graph_attr=dict(size="12,12"))
    seen = set()

    def size_to_str(size):
        return '('+(', ').join(['%d' % v for v in size])+')'

    def add_nodes(var):
        if var not in seen:
            if torch.is_tensor(var):
                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')
            elif hasattr(var, 'variable'):
                u = var.variable
                name = param_map[id(u)] if params is not None else ''
                node_name = '%s\n %s' % (name, size_to_str(u.size()))
                dot.node(str(id(var)), node_name, fillcolor='lightblue')
            else:
                dot.node(str(id(var)), str(type(var).__name__))
            seen.add(var)
            if hasattr(var, 'next_functions'):
                for u in var.next_functions:
                    if u[0] is not None:
                        dot.edge(str(id(u[0])), str(id(var)))
                        add_nodes(u[0])
            if hasattr(var, 'saved_tensors'):
                for t in var.saved_tensors:
                    dot.edge(str(id(t)), str(id(var)))
                    add_nodes(t)
    add_nodes(var.grad_fn)
    return dot

make_dot(output).view()

import os
glaucoma_dir = '/content/drive/My Drive/magisterka/glaucoma/train'
glaucoma_len= len([name for name in os.listdir(glaucoma_dir) if os.path.isfile(os.path.join(glaucoma_dir, name))])
print(glaucoma_len) 

retinopathy_dir = '/content/drive/My Drive/magisterka/diabetic retinopathy/train'
retinopathy_len= len([name for name in os.listdir(retinopathy_dir) if os.path.isfile(os.path.join(retinopathy_dir, name))])
print(retinopathy_len) 

amd_dir = '/content/drive/My Drive/magisterka/amd/train'
amd_len= len([name for name in os.listdir(amd_dir) if os.path.isfile(os.path.join(amd_dir, name))])
print(amd_len)